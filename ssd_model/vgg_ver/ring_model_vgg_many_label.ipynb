{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "###### 7/1　選定したringで学習\n",
    "### 8/10　学習データを更新"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "from math import sqrt as sqrt\n",
    "from itertools import product as product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "import ast\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from utils.ssd_model import SSD\n",
    "from utils.ssd_model import MultiBoxLoss\n",
    "from utils.ssd_model import decode"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, path, patience=7, verbose=False, delta=0, trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "input_size = 300\n",
    "color_mean = (0, 0)\n",
    "voc_classes = ['ring']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "ssd_cfg = {\n",
    "    'num_classes': 2,  # 背景クラスを含めた合計クラス数\n",
    "    'input_size': input_size,  # 画像の入力サイズ\n",
    "#     'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
    "    'bbox_aspect_num': [4, 4, 4, 4, 4, 4],\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ   \n",
    "#     'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
    "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
    "    'aspect_ratios': [[2], [2], [2], [2], [2], [2]],\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_label = pd.read_csv('../data_for_ssd/MWP_data/ring_selection_for_ssd/seirei_hurei/train_label.csv')\n",
    "train_data = np.load('../data_for_ssd/MWP_data/ring_selection_for_ssd/seirei_hurei/train.npy')\n",
    "val_label = pd.read_csv('../data_for_ssd/MWP_data/ring_selection_for_ssd/seirei_hurei/val_label.csv')\n",
    "val_data = np.load('../data_for_ssd/MWP_data/ring_selection_for_ssd/seirei_hurei/val.npy')\n",
    "\n",
    "train_data = train_data[:,:,:,:2]\n",
    "train_data = np.swapaxes(train_data, 2, 3)\n",
    "train_data = np.swapaxes(train_data, 1, 2)\n",
    "\n",
    "val_data = val_data[:,:,:,:2]\n",
    "val_data = np.swapaxes(val_data, 2, 3)\n",
    "val_data = np.swapaxes(val_data, 1, 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(len(train_label),train_data.shape)\n",
    "print(len(val_label),val_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12184 (12184, 2, 300, 300)\n",
      "462 (462, 2, 300, 300)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_label = train_label.drop('Unnamed: 0', axis=1)\n",
    "val_label = val_label.drop('Unnamed: 0', axis=1)\n",
    "# label = label.drop('index', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_label['xmin'] = [ast.literal_eval(d) for d in train_label['xmin']]\n",
    "train_label['xmax'] = [ast.literal_eval(d) for d in train_label['xmax']]\n",
    "train_label['ymin'] = [ast.literal_eval(d) for d in train_label['ymin']]\n",
    "train_label['ymax'] = [ast.literal_eval(d) for d in train_label['ymax']]\n",
    "\n",
    "val_label['xmin'] = [ast.literal_eval(d) for d in val_label['xmin']]\n",
    "val_label['xmax'] = [ast.literal_eval(d) for d in val_label['xmax']]\n",
    "val_label['ymin'] = [ast.literal_eval(d) for d in val_label['ymin']]\n",
    "val_label['ymax'] = [ast.literal_eval(d) for d in val_label['ymax']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_label_list = []\n",
    "for i in range(len(train_label)):\n",
    "    lab = []\n",
    "    for k in range(len(train_label['xmin'][i])):\n",
    "        labe = []\n",
    "        labe.append(train_label['xmin'][i][k])\n",
    "        labe.append(train_label['ymin'][i][k])\n",
    "        labe.append(train_label['xmax'][i][k])\n",
    "        labe.append(train_label['ymax'][i][k])\n",
    "        labe.append(0)\n",
    "        lab.append(labe)\n",
    "    train_label_list.append(np.array(lab))\n",
    "\n",
    "val_label_list = []\n",
    "for i in range(len(val_label)):\n",
    "    lab = []\n",
    "    for k in range(len(val_label['xmin'][i])):\n",
    "        labe = []\n",
    "        labe.append(val_label['xmin'][i][k])\n",
    "        labe.append(val_label['ymin'][i][k])\n",
    "        labe.append(val_label['xmax'][i][k])\n",
    "        labe.append(val_label['ymax'][i][k])\n",
    "        labe.append(0)\n",
    "        lab.append(labe)\n",
    "    val_label_list.append(np.array(lab))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "val_label_list[1].shape, val_label_list[-1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1, 5), (0,))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# kf = KFold(n_splits=2, shuffle=True)\n",
    "# train_data_list = []\n",
    "# train_label_list = []\n",
    "# test_data_list = []\n",
    "# test_label_list = []\n",
    "# for train_index, test_index in kf.split(data, label_list):\n",
    "#     train_data_list.append(data[train_index])\n",
    "#     train_label_list.append([label_list[k] for k in train_index])\n",
    "#     test_data_list.append(data[test_index])\n",
    "#     test_label_list.append([label_list[k] for k in test_index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(len(train_label_list), len(val_label_list))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12184 462\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_data.shape, val_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((12184, 2, 300, 300), (462, 2, 300, 300))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def od_collate_fn(batch):\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])\n",
    "        targets.append(torch.FloatTensor(sample[1]))\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "        \n",
    "    return imgs, targets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# for d in train_data_list[0]:\n",
    "#     if sum(np.isnan(d.ravel())) == 0:\n",
    "#         pass\n",
    "#     else:\n",
    "#         print('neko')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "class DataSet():\n",
    "    def __init__(self, data, label):\n",
    "        self.label = label\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "batch_size = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "train_dataset = DataSet(torch.Tensor(train_data), train_label_list)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "\n",
    "test_dataset = DataSet(torch.Tensor(val_data), val_label_list)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dataloaders_dict = {\"train\": train_loader, \"val\": test_loader}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "net = SSD(phase='train', cfg=ssd_cfg)\n",
    "# CNN_weight = torch.load('ssd300_mAP_77.43_v2.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# net.vgg[0].weight = nn.Parameter(CNN_weight['vgg.0.weight'][:,:2,:,:])#.detach().numpy().copy()\n",
    "# net.vgg[0].bias = nn.Parameter(CNN_weight['vgg.0.bias'])\n",
    "# net.vgg[2].weight = nn.Parameter(CNN_weight['vgg.2.weight'])\n",
    "# net.vgg[2].bias = nn.Parameter(CNN_weight['vgg.2.bias'])\n",
    "# net.vgg[5].weight = nn.Parameter(CNN_weight['vgg.5.weight'])\n",
    "# net.vgg[5].bias = nn.Parameter(CNN_weight['vgg.5.bias'])\n",
    "# net.vgg[7].weight = nn.Parameter(CNN_weight['vgg.7.weight'])\n",
    "# net.vgg[7].bias = nn.Parameter(CNN_weight['vgg.7.bias'])\n",
    "# net.vgg[10].weight = nn.Parameter(CNN_weight['vgg.10.weight'])\n",
    "# net.vgg[10].bias = nn.Parameter(CNN_weight['vgg.10.bias'])\n",
    "# net.vgg[12].weight = nn.Parameter(CNN_weight['vgg.12.weight'])\n",
    "# net.vgg[12].bias = nn.Parameter(CNN_weight['vgg.12.bias'])\n",
    "# net.vgg[14].weight = nn.Parameter(CNN_weight['vgg.14.weight'])\n",
    "# net.vgg[14].bias = nn.Parameter(CNN_weight['vgg.14.bias'])\n",
    "# net.vgg[17].weight = nn.Parameter(CNN_weight['vgg.17.weight'])\n",
    "# net.vgg[17].bias = nn.Parameter(CNN_weight['vgg.17.bias'])\n",
    "# net.vgg[19].weight = nn.Parameter(CNN_weight['vgg.19.weight'])\n",
    "# net.vgg[19].bias = nn.Parameter(CNN_weight['vgg.19.bias'])\n",
    "# net.vgg[21].weight = nn.Parameter(CNN_weight['vgg.21.weight'])\n",
    "# net.vgg[21].bias = nn.Parameter(CNN_weight['vgg.21.bias'])\n",
    "# net.vgg[24].weight = nn.Parameter(CNN_weight['vgg.24.weight'])\n",
    "# net.vgg[24].bias = nn.Parameter(CNN_weight['vgg.24.bias'])\n",
    "# net.vgg[26].weight = nn.Parameter(CNN_weight['vgg.26.weight'])\n",
    "# net.vgg[26].bias = nn.Parameter(CNN_weight['vgg.26.bias'])\n",
    "# net.vgg[28].weight = nn.Parameter(CNN_weight['vgg.28.weight'])\n",
    "# net.vgg[28].bias = nn.Parameter(CNN_weight['vgg.28.bias'])\n",
    "# net.vgg[31].weight = nn.Parameter(CNN_weight['vgg.31.weight'])\n",
    "# net.vgg[31].bias = nn.Parameter(CNN_weight['vgg.31.bias'])\n",
    "# net.vgg[33].weight = nn.Parameter(CNN_weight['vgg.33.weight'])\n",
    "# net.vgg[33].bias = nn.Parameter(CNN_weight['vgg.33.bias'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (vgg): ModuleList(\n",
       "    (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Sequential(\n",
       "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Sequential(\n",
       "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (34): ReLU(inplace=True)\n",
       "  )\n",
       "  (extras): ModuleList(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (L2Norm): L2Norm()\n",
       "  (loc): ModuleList(\n",
       "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList(\n",
       "    (0): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "summary(net, (2, 300, 300))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 300, 300]           1,216\n",
      "              ReLU-2         [-1, 64, 300, 300]               0\n",
      "       BatchNorm2d-3         [-1, 64, 300, 300]             128\n",
      "            Conv2d-4         [-1, 64, 300, 300]          36,928\n",
      "              ReLU-5         [-1, 64, 300, 300]               0\n",
      "         MaxPool2d-6         [-1, 64, 150, 150]               0\n",
      "            Conv2d-7        [-1, 128, 150, 150]          73,856\n",
      "              ReLU-8        [-1, 128, 150, 150]               0\n",
      "       BatchNorm2d-9        [-1, 128, 150, 150]             256\n",
      "           Conv2d-10        [-1, 128, 150, 150]         147,584\n",
      "             ReLU-11        [-1, 128, 150, 150]               0\n",
      "        MaxPool2d-12          [-1, 128, 75, 75]               0\n",
      "           Conv2d-13          [-1, 256, 75, 75]         295,168\n",
      "             ReLU-14          [-1, 256, 75, 75]               0\n",
      "      BatchNorm2d-15          [-1, 256, 75, 75]             512\n",
      "           Conv2d-16          [-1, 256, 75, 75]         590,080\n",
      "             ReLU-17          [-1, 256, 75, 75]               0\n",
      "           Conv2d-18          [-1, 256, 75, 75]         590,080\n",
      "             ReLU-19          [-1, 256, 75, 75]               0\n",
      "        MaxPool2d-20          [-1, 256, 38, 38]               0\n",
      "           Conv2d-21          [-1, 512, 38, 38]       1,180,160\n",
      "             ReLU-22          [-1, 512, 38, 38]               0\n",
      "      BatchNorm2d-23          [-1, 512, 38, 38]           1,024\n",
      "           Conv2d-24          [-1, 512, 38, 38]       2,359,808\n",
      "             ReLU-25          [-1, 512, 38, 38]               0\n",
      "           Conv2d-26          [-1, 512, 38, 38]       2,359,808\n",
      "             ReLU-27          [-1, 512, 38, 38]               0\n",
      "           L2Norm-28          [-1, 512, 38, 38]             512\n",
      "        MaxPool2d-29          [-1, 512, 19, 19]               0\n",
      "           Conv2d-30          [-1, 512, 19, 19]       2,359,808\n",
      "             ReLU-31          [-1, 512, 19, 19]               0\n",
      "      BatchNorm2d-32          [-1, 512, 19, 19]           1,024\n",
      "           Conv2d-33          [-1, 512, 19, 19]       2,359,808\n",
      "             ReLU-34          [-1, 512, 19, 19]               0\n",
      "           Conv2d-35          [-1, 512, 19, 19]       2,359,808\n",
      "             ReLU-36          [-1, 512, 19, 19]               0\n",
      "        MaxPool2d-37          [-1, 512, 19, 19]               0\n",
      "           Conv2d-38         [-1, 1024, 19, 19]       4,719,616\n",
      "             ReLU-39         [-1, 1024, 19, 19]               0\n",
      "      BatchNorm2d-40         [-1, 1024, 19, 19]           2,048\n",
      "           Conv2d-41         [-1, 1024, 19, 19]       1,049,600\n",
      "             ReLU-42         [-1, 1024, 19, 19]               0\n",
      "           Conv2d-43          [-1, 256, 19, 19]         262,400\n",
      "           Conv2d-44          [-1, 512, 10, 10]       1,180,160\n",
      "           Conv2d-45          [-1, 128, 10, 10]          65,664\n",
      "           Conv2d-46            [-1, 256, 5, 5]         295,168\n",
      "           Conv2d-47            [-1, 128, 5, 5]          32,896\n",
      "           Conv2d-48            [-1, 256, 3, 3]         295,168\n",
      "           Conv2d-49            [-1, 128, 3, 3]          32,896\n",
      "           Conv2d-50            [-1, 256, 1, 1]         295,168\n",
      "           Conv2d-51           [-1, 16, 38, 38]          73,744\n",
      "           Conv2d-52            [-1, 8, 38, 38]          36,872\n",
      "           Conv2d-53           [-1, 16, 19, 19]         147,472\n",
      "           Conv2d-54            [-1, 8, 19, 19]          73,736\n",
      "           Conv2d-55           [-1, 16, 10, 10]          73,744\n",
      "           Conv2d-56            [-1, 8, 10, 10]          36,872\n",
      "           Conv2d-57             [-1, 16, 5, 5]          36,880\n",
      "           Conv2d-58              [-1, 8, 5, 5]          18,440\n",
      "           Conv2d-59             [-1, 16, 3, 3]          36,880\n",
      "           Conv2d-60              [-1, 8, 3, 3]          18,440\n",
      "           Conv2d-61             [-1, 16, 1, 1]           4,112\n",
      "           Conv2d-62              [-1, 8, 1, 1]           2,056\n",
      "================================================================\n",
      "Total params: 23,507,600\n",
      "Trainable params: 23,507,600\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.69\n",
      "Forward/backward pass size (MB): 499.36\n",
      "Params size (MB): 89.67\n",
      "Estimated Total Size (MB): 589.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "net.vgg.apply(weights_init)\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(1024, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# for i in net.parameters():\n",
    "#     print(i.requires_grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "list_ = []\n",
    "for i in net.parameters():\n",
    "    i = i.to('cpu').detach().numpy().ravel()\n",
    "    list_.append(i)\n",
    "    pass\n",
    "\n",
    "list_ = np.concatenate(list_)\n",
    "plt.hist(list_, bins=np.linspace(-0.5, 0.5, 50))\n",
    "plt.show"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=False)\n",
    "# optimizer = optim.RMSprop(net.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, file_name):\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    train_precision_list = []\n",
    "    train_recall_025_under_list = []\n",
    "    train_recall_025_upper_list = []\n",
    "    val_precision_list = []\n",
    "    val_recall_025_under_list = []\n",
    "    val_recall_025_upper_list = []\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True, path='weights/%s/earlystopping.pth'%(file_name))\n",
    "    # イテレーションカウンタをセット\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        iteration = 0\n",
    "        val_iter = 0\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    " \n",
    "        \n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "        \n",
    "        train_bbbb = []\n",
    "        train_seikai = []\n",
    "        val_bbbb = []\n",
    "        val_seikai = []\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                print('（train）')\n",
    "            else:\n",
    "                net.eval()\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "                \n",
    "                \n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                images = images.to(device, dtype=torch.float)\n",
    "                targets = [ann.to(device, dtype=torch.float) for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 順伝搬（forward）計算\n",
    "                    outputs, decoded_box = net(images)\n",
    "\n",
    "                    conf = softmax(outputs[1])\n",
    "                    bbb = np.concatenate([conf[:, :, 1].to('cpu').detach().numpy()[:,:,None], \n",
    "                                             decoded_box.detach().numpy()], axis=2)\n",
    "\n",
    "\n",
    "                    # 損失の計算\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "            \n",
    "#                     訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        train_seikai.extend([ann.to('cpu').detach().numpy() for ann in targets])\n",
    "                        train_bbbb.append(bbb)\n",
    "                        \n",
    "                        loss.backward()  # 勾配の計算\n",
    "#                         nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
    "\n",
    "                        optimizer.step()  # パラメータ更新\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        print(\"\\r\"+str(iteration)+'/'+str(int(train_data.shape[0]/batch_size))+'       ', end=\"\")\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        val_seikai.extend([ann.to('cpu').detach().numpy() for ann in targets])\n",
    "                        val_bbbb.append(bbb)\n",
    "                        \n",
    "                        epoch_val_loss += loss.item()\n",
    "                        val_iter += 1  \n",
    "\n",
    "        avg_train_loss = epoch_train_loss / iteration\n",
    "        avg_val_loss = epoch_val_loss / val_iter\n",
    "    \n",
    "        print('\\nepoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f} '.format(epoch+1,\n",
    "                                                                                  avg_train_loss,\n",
    "                                                                                  avg_val_loss))\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': avg_train_loss, 'val_loss': avg_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"weights/%s/log_output.csv\"%(file_name))\n",
    "        \n",
    "        early_stopping(epoch_val_loss, net)\n",
    "    \n",
    "        if early_stopping.early_stop:\n",
    "            train_bbbb = np.concatenate(train_bbbb, axis=0)\n",
    "            val_bbbb = np.concatenate(val_bbbb, axis=0)\n",
    "            print(train_bbbb.shape, val_bbbb.shape)\n",
    "\n",
    "            print('Early_Stopping')\n",
    "            break\n",
    "            \n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        # ネットワークを保存する\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), 'weights/%s/ssd300_'%(file_name) +\n",
    "                       str(epoch+1) + '.pth')\n",
    "            \n",
    "    return train_bbbb, val_bbbb, train_seikai, val_seikai"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "save_folder = 'add_hurei_9_9_batchnorm'\n",
    "num_epoch = 300\n",
    "pd_frame = pd.DataFrame(columns=['iteration', 'phase', 'loss'])\n",
    "# train_model(net, dataloaders_dict , criterion, optimizer, num_epochs=num_epoch, file_name='tamesi')\n",
    "                                                \n",
    "# train_precision_list, train_recall_025_under_list, train_recall_025_upper_list, \\\n",
    "# val_precision_list, val_recall_025_under_list, val_recall_025_upper_list\\\n",
    "# = train_model(net, dataloaders_dict , criterion, optimizer,\n",
    "#                         num_epochs=num_epoch, file_name='tamesi')\n",
    "\n",
    "train_bbbb, val_bbbb, train_seikai, val_seikai\\\n",
    "= train_model(net, dataloaders_dict , criterion, optimizer,\n",
    "                        num_epochs=num_epoch, file_name=save_folder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用デバイス： cuda:0\n",
      "-------------\n",
      "Epoch 1/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 1 || Epoch_TRAIN_Loss:4.7168 ||Epoch_VAL_Loss:3.9187 \n",
      "timer:  205.8336 sec.\n",
      "Validation loss decreased (inf --> 58.780839).  Saving model ...\n",
      "-------------\n",
      "Epoch 2/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 2 || Epoch_TRAIN_Loss:3.4695 ||Epoch_VAL_Loss:3.6128 \n",
      "timer:  204.1885 sec.\n",
      "Validation loss decreased (58.780839 --> 54.192284).  Saving model ...\n",
      "-------------\n",
      "Epoch 3/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 3 || Epoch_TRAIN_Loss:3.1196 ||Epoch_VAL_Loss:3.3729 \n",
      "timer:  204.1870 sec.\n",
      "Validation loss decreased (54.192284 --> 50.592854).  Saving model ...\n",
      "-------------\n",
      "Epoch 4/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 4 || Epoch_TRAIN_Loss:2.8027 ||Epoch_VAL_Loss:3.2178 \n",
      "timer:  204.3371 sec.\n",
      "Validation loss decreased (50.592854 --> 48.267547).  Saving model ...\n",
      "-------------\n",
      "Epoch 5/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 5 || Epoch_TRAIN_Loss:2.4782 ||Epoch_VAL_Loss:2.7506 \n",
      "timer:  204.3978 sec.\n",
      "Validation loss decreased (48.267547 --> 41.258998).  Saving model ...\n",
      "-------------\n",
      "Epoch 6/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 6 || Epoch_TRAIN_Loss:2.2570 ||Epoch_VAL_Loss:2.5469 \n",
      "timer:  204.5126 sec.\n",
      "Validation loss decreased (41.258998 --> 38.203642).  Saving model ...\n",
      "-------------\n",
      "Epoch 7/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 7 || Epoch_TRAIN_Loss:2.0638 ||Epoch_VAL_Loss:2.4858 \n",
      "timer:  204.5262 sec.\n",
      "Validation loss decreased (38.203642 --> 37.287245).  Saving model ...\n",
      "-------------\n",
      "Epoch 8/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 8 || Epoch_TRAIN_Loss:1.8709 ||Epoch_VAL_Loss:2.8525 \n",
      "timer:  204.2338 sec.\n",
      "EarlyStopping counter: 1 out of 10\n",
      "-------------\n",
      "Epoch 9/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 9 || Epoch_TRAIN_Loss:1.7206 ||Epoch_VAL_Loss:3.7420 \n",
      "timer:  203.9595 sec.\n",
      "EarlyStopping counter: 2 out of 10\n",
      "-------------\n",
      "Epoch 10/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 10 || Epoch_TRAIN_Loss:1.6027 ||Epoch_VAL_Loss:2.6367 \n",
      "timer:  204.1048 sec.\n",
      "EarlyStopping counter: 3 out of 10\n",
      "-------------\n",
      "Epoch 11/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 11 || Epoch_TRAIN_Loss:1.4666 ||Epoch_VAL_Loss:2.7560 \n",
      "timer:  204.1452 sec.\n",
      "EarlyStopping counter: 4 out of 10\n",
      "-------------\n",
      "Epoch 12/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 12 || Epoch_TRAIN_Loss:1.3329 ||Epoch_VAL_Loss:2.9493 \n",
      "timer:  203.8797 sec.\n",
      "EarlyStopping counter: 5 out of 10\n",
      "-------------\n",
      "Epoch 13/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 13 || Epoch_TRAIN_Loss:1.2083 ||Epoch_VAL_Loss:3.3664 \n",
      "timer:  204.2393 sec.\n",
      "EarlyStopping counter: 6 out of 10\n",
      "-------------\n",
      "Epoch 14/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 14 || Epoch_TRAIN_Loss:1.0888 ||Epoch_VAL_Loss:3.1135 \n",
      "timer:  204.3744 sec.\n",
      "EarlyStopping counter: 7 out of 10\n",
      "-------------\n",
      "Epoch 15/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 15 || Epoch_TRAIN_Loss:0.9773 ||Epoch_VAL_Loss:3.0264 \n",
      "timer:  204.2457 sec.\n",
      "EarlyStopping counter: 8 out of 10\n",
      "-------------\n",
      "Epoch 16/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 16 || Epoch_TRAIN_Loss:0.9013 ||Epoch_VAL_Loss:3.2821 \n",
      "timer:  204.2489 sec.\n",
      "EarlyStopping counter: 9 out of 10\n",
      "-------------\n",
      "Epoch 17/300\n",
      "-------------\n",
      "（train）\n",
      "380/380       \n",
      "epoch 17 || Epoch_TRAIN_Loss:0.8130 ||Epoch_VAL_Loss:3.4441 \n",
      "timer:  203.8922 sec.\n",
      "EarlyStopping counter: 10 out of 10\n",
      "(12184, 7760, 5) (462, 7760, 5)\n",
      "Early_Stopping\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "np.save('weights/add_hurei_9_9_batchnorm/train_bbbb.npy', train_bbbb)\n",
    "np.save('weights/add_hurei_9_9_batchnorm/val_bbbb.npy', val_bbbb)\n",
    "f = open('weights/add_hurei_9_9_batchnorm/train_seikai.txt', 'wb')\n",
    "pickle.dump(train_seikai, f)\n",
    "f = open('weights/add_hurei_9_9_batchnorm/val_seikai.txt', 'wb')\n",
    "pickle.dump(val_seikai, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}